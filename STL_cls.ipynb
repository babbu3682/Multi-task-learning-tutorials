{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "STL_cls.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKdq8T9oEF_n",
        "outputId": "cd8d5eb0-ee06-4d0e-e409-8042b1be5b9b"
      },
      "source": [
        "# Install required libs\n",
        "!sudo pip install -U segmentation-models-pytorch albumentations scikit-image monai --user --upgrade"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: segmentation-models-pytorch in /root/.local/lib/python3.7/site-packages (0.2.0)\n",
            "Requirement already satisfied: albumentations in /root/.local/lib/python3.7/site-packages (1.0.3)\n",
            "Requirement already satisfied: scikit-image in /root/.local/lib/python3.7/site-packages (0.18.3)\n",
            "Collecting monai\n",
            "  Downloading monai-0.6.0-202107081903-py3-none-any.whl (584 kB)\n",
            "\u001b[K     |████████████████████████████████| 584 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: timm==0.4.12 in /root/.local/lib/python3.7/site-packages (from segmentation-models-pytorch) (0.4.12)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.6.3 in /root/.local/lib/python3.7/site-packages (from segmentation-models-pytorch) (0.6.3)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (0.10.0+cu102)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /root/.local/lib/python3.7/site-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch) (1.9.0+cu102)\n",
            "Requirement already satisfied: munch in /root/.local/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (2.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.62.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.19.5)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /root/.local/lib/python3.7/site-packages (from albumentations) (4.5.3.56)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.8.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
            "Installing collected packages: monai\n",
            "Successfully installed monai-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3MAK-ZuEF_q"
      },
      "source": [
        "# !sudo pip install scikit-image"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAyRqli6EF_r"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t85Nx2fQEF_s",
        "outputId": "e0f4d802-4bba-4929-adfe-ce551fab62bc"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "!nvidia-smi\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import glob, natsort"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep 11 04:26:42 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyPDCEXZFzqc",
        "outputId": "a5cc9410-f548-4bd9-b256-f89b31b3dec3"
      },
      "source": [
        "!git clone https://github.com/kevinkwshin/MTL.git\n",
        "%cd MTL"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MTL' already exists and is not an empty directory.\n",
            "/content/MTL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gil7jRRlEUHo"
      },
      "source": [
        "!cat SSIM_cls.tar.gz* | tar -zxvpf -\n",
        "!cat SSIM_seg.tar.gz* | tar -zxvpf -"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp5-EVvHEF_u"
      },
      "source": [
        "!nvidia-smi\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import glob, natsort"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mSKFHLtEF_u"
      },
      "source": [
        "def count_nonzeros(flist):\n",
        "    count = 0\n",
        "    for idx in range(len(flist)):\n",
        "        fname = flist[idx]\n",
        "        mask = cv2.imread(fname)\n",
        "        mask[mask!= 0] = 255\n",
        "        if len(np.unique(mask))!= 1:\n",
        "            count += 1\n",
        "    P = count\n",
        "    N = len(flist) - P\n",
        "    print('P: {} ({:.2f}%) N: {} ({:.2f}%) Total: {}'.format(P, P/len(flist)*100, N, N/len(flist)*100, P+N))\n",
        "\n",
        "flist = glob.glob('SSIM_seg/trainannot/*')\n",
        "count_nonzeros(flist)\n",
        "flist = glob.glob('SSIM_seg/valannot/*')\n",
        "count_nonzeros(flist)\n",
        "flist = glob.glob('SSIM_seg/testannot/*')\n",
        "count_nonzeros(flist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtyBx6PJEF_v"
      },
      "source": [
        "# list_x = natsort.natsorted(glob.glob('SSIM_seg/train/'))\n",
        "# list_y = natsort.natsorted(glob.glob('SSIM_seg/trainannot/'))\n",
        "\n",
        "# list_x = natsort.natsorted(glob.glob('SSIM_seg/val/'))\n",
        "# list_y = natsort.natsorted(glob.glob('SSIM_seg/valannot/'))\n",
        "\n",
        "# list_x = natsort.natsorted(glob.glob('SSIM_seg/test/'))\n",
        "# list_y = natsort.natsorted(glob.glob('SSIM_seg/testannot/'))\n",
        "\n",
        "# list_x = natsort.natsorted(glob.glob('SSIM_cls/train/'))\n",
        "# list_y = natsort.natsorted(glob.glob('SSIM_cls/trainannot/'))\n",
        "\n",
        "# list_x = natsort.natsorted(glob.glob('SSIM_cls/val/*'))\n",
        "# list_y = natsort.natsorted(glob.glob('SSIM_cls/valannot/*'))\n",
        "\n",
        "# list_x = natsort.natsorted(glob.glob('SSIM_cls/test/*'))\n",
        "# list_y = natsort.natsorted(glob.glob('SSIM_cls/testannot/*'))\n",
        "\n",
        "# for idx in range(len(list_x)):\n",
        "#     if list_x[idx].split('/')[-1][:-3] != list_y[idx].split('/')[-1][:-3]:\n",
        "#         print(idx,list_x[idx],list_y[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN3SCwTVEF_v"
      },
      "source": [
        "DATA_DIR = './SSIM_cls/'\n",
        "\n",
        "x_train_dir = os.path.join(DATA_DIR, 'train')\n",
        "y_train_dir = os.path.join(DATA_DIR, 'trainannot')\n",
        "\n",
        "x_valid_dir = os.path.join(DATA_DIR, 'val')\n",
        "y_valid_dir = os.path.join(DATA_DIR, 'valannot')\n",
        "\n",
        "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
        "y_test_dir = os.path.join(DATA_DIR, 'testannot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EMn7RnPEF_v"
      },
      "source": [
        "# helper function for data visualization\n",
        "def visualize(**images):\n",
        "    \"\"\"Plot images in one row.\"\"\"\n",
        "    \n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        if torch.is_tensor(image):\n",
        "            image = image.permute(1,2,0)#.int()\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image,cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew-bYnMsEF_w"
      },
      "source": [
        "### Dataloader\n",
        "\n",
        "Writing helper class for data extraction, tranformation and preprocessing  \n",
        "https://pytorch.org/docs/stable/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpwEmmjXEF_w"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset as BaseDataset\n",
        "import pylab as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0iPTFh_EF_w"
      },
      "source": [
        "class Dataset(BaseDataset):\n",
        "    \"\"\"\n",
        "    \n",
        "    Args:\n",
        "        images_dir (str): path to images folder\n",
        "        masks_dir (str): path to segmentation masks folder\n",
        "        augmentation (albumentations.Compose): data transfromation pipeline \n",
        "            (e.g. flip, scale, etc.)\n",
        "        preprocessing (albumentations.Compose): data preprocessing \n",
        "            (e.g. noralization, shape manipulation, etc.)\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "            self, \n",
        "            images_dir, \n",
        "            masks_dir, \n",
        "            augmentation=None, \n",
        "    ):\n",
        "        self.images_fps = natsort.natsorted(glob.glob(images_dir+'/*'))\n",
        "        self.masks_fps = natsort.natsorted(glob.glob(masks_dir+'/*'))\n",
        "        self.augmentation = augmentation\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # read data\n",
        "        image = cv2.imread(self.images_fps[i])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        fname = self.masks_fps[i]        \n",
        "        if fname[-3:] == 'png':\n",
        "            mask = cv2.imread(self.masks_fps[i], 0)\n",
        "            mask = np.expand_dims(mask,-1)\n",
        "            mask[mask!=0] = 1\n",
        "            gt = np.array([1]) if np.count_nonzero(mask) else np.array([0])\n",
        "            gt = gt.astype(np.float32)\n",
        "        else:\n",
        "            gt = np.load(self.masks_fps[i])\n",
        "            gt = gt.astype(np.float32)\n",
        "            mask = np.zeros_like(image)\n",
        "            mask[mask==0] = 100\n",
        "            \n",
        "        # apply augmentations\n",
        "        if self.augmentation:\n",
        "            if -100 in mask:\n",
        "                sample = self.augmentation(image=image)\n",
        "                image = sample['image']\n",
        "            else:\n",
        "                sample = self.augmentation(image=image, mask=mask)\n",
        "                image, mask = sample['image'], sample['mask']\n",
        "        \n",
        "        image = image.astype(np.float32)\n",
        "        image = image/255.\n",
        "        image = np.moveaxis(image,-1,0)\n",
        "        image = torch.tensor(image)\n",
        "        mask = mask.astype(np.float32)\n",
        "        mask = np.moveaxis(mask,-1,0)\n",
        "        mask = torch.tensor(mask)\n",
        "        gt = torch.tensor(gt)\n",
        "            \n",
        "        return {'x' : image, 'y_seg' : mask, 'y_cls' : gt}\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.images_fps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moWT-7XKEF_x"
      },
      "source": [
        "### Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M552nzgfEF_x"
      },
      "source": [
        "import albumentations as albu\n",
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "\n",
        "        albu.HorizontalFlip(p=0.5),\n",
        "        albu.ShiftScaleRotate(scale_limit=0.05, rotate_limit=10, shift_limit=0.02, border_mode=4, p=.5),\n",
        "        albu.IAAAdditiveGaussianNoise(scale=(1, 5),p=0.2),\n",
        "        albu.IAAPerspective(scale=(0.01, 0.02),p=0.5),\n",
        "        \n",
        "        albu.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=False, p=0.5),\n",
        "        albu.RandomGamma(gamma_limit=(80,120), p=.5),\n",
        "        albu.RandomToneCurve(scale=0.1,p=.5), \n",
        "        albu.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=.5),\n",
        "\n",
        "        albu.OneOf(\n",
        "            [\n",
        "                albu.IAASharpen(p=.5),        \n",
        "                albu.GaussNoise(var_limit=0.02, mean=0, p=0.5),\n",
        "                albu.MultiplicativeNoise(multiplier=(0.98, 1.02), p=0.5),\n",
        "                albu.ISONoise(color_shift=(0.01, 0.02),intensity=(0.1, 0.3),p=0.5),\n",
        "            ],\n",
        "            p=0.5,\n",
        "        ),\n",
        "    ]\n",
        "    return albu.Compose(train_transform)\n",
        "\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
        "    test_transform = [\n",
        "\n",
        "    ]\n",
        "    return albu.Compose(test_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RLBpcF7eEF_y"
      },
      "source": [
        "train_dataset = Dataset(\n",
        "    x_train_dir, \n",
        "    y_train_dir, \n",
        "    augmentation=get_training_augmentation(), \n",
        "#     preprocessing=get_preprocessing(),\n",
        ")\n",
        "# \n",
        "valid_dataset = Dataset(\n",
        "    x_valid_dir, \n",
        "    y_valid_dir, \n",
        "    augmentation=get_validation_augmentation(), \n",
        "#     preprocessing=get_preprocessing(),\n",
        ") \n",
        "\n",
        "test_dataset = Dataset(\n",
        "    x_test_dir, \n",
        "    y_test_dir, \n",
        "    augmentation=get_validation_augmentation(), \n",
        "#     preprocessing=get_preprocessing(),\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdMO4sJyEF_z"
      },
      "source": [
        "# same image with different random transforms\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "x = batch['x'][0]\n",
        "y_seg = batch['y_seg'][0]\n",
        "y_cls = batch['y_cls'][0]\n",
        "\n",
        "print(x.shape,y_seg.shape,y_cls.shape)\n",
        "print(torch.unique(y_seg),y_cls)\n",
        "visualize(image=x, mask=y_seg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJR5DIj4EF_z"
      },
      "source": [
        "## Create model and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVwnh_bUEF_z"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import segmentation_models_pytorch as smp\n",
        "import tqdm\n",
        "from tqdm import trange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWB8vp_ZEF_z"
      },
      "source": [
        "# ENCODER = 'resnet152'\n",
        "\n",
        "# ENCODER_WEIGHTS = 'imagenet'\n",
        "# ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
        "# DEVICE = 'cuda'\n",
        "\n",
        "# aux_params=dict(\n",
        "#     pooling='avg',             # one of 'avg', 'max'\n",
        "#     dropout=0.5,               # dropout ratio, default is None\n",
        "#     activation='sigmoid',      # activation function, default is None\n",
        "#     classes=1,                 # define number of output labels\n",
        "# )\n",
        "# # aux_params=None\n",
        "\n",
        "# # create segmentation model with pretrained encoder\n",
        "# model = smp.Unet(\n",
        "#     encoder_name=ENCODER, \n",
        "#     encoder_weights=ENCODER_WEIGHTS, \n",
        "#     classes=1, \n",
        "#     activation=ACTIVATION,\n",
        "#     aux_params = aux_params,\n",
        "# ).cuda()\n",
        "\n",
        "import torchvision.models as tmodels\n",
        "model = tmodels.resnet152(pretrained=True)\n",
        "model.fc = nn.Sequential(nn.Linear(2048,1000),nn.Linear(1000,1),nn.Sigmoid())\n",
        "model = model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojQz_ZNgEF_0"
      },
      "source": [
        "import monai\n",
        "import sklearn\n",
        "import sklearn.metrics\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self):        \n",
        "        super(DiceBCELoss, self).__init__()\n",
        "        self.dice = monai.losses.GeneralizedDiceLoss(sigmoid=False)\n",
        "        self.ce = nn.BCELoss()        \n",
        "        \n",
        "    def forward(self,yhat,y):\n",
        "        dice = self.dice(yhat,y)\n",
        "        ce = self.ce(yhat,y)\n",
        "        return dice+ce\n",
        "\n",
        "class CELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CELoss, self).__init__()\n",
        "        self.ce = nn.CrossEntropyLoss(ignore_index= 100)\n",
        "        \n",
        "    def forward(self,yhat,y):\n",
        "        y = y[:,0].long()\n",
        "        loss = self.ce(yhat,y)\n",
        "        return loss \n",
        "\n",
        "class DiceCELoss(nn.Module):\n",
        "    def __init__(self):        \n",
        "        super(DiceCELoss, self).__init__()\n",
        "        self.dice = monai.losses.GeneralizedDiceLoss(to_onehot_y=True)\n",
        "        self.ce = CELoss()        \n",
        "        \n",
        "    def forward(self,yhat,y):\n",
        "        dice = self.dice(yhat,y)\n",
        "        ce = self.ce(yhat,y)\n",
        "        return dice+ce\n",
        "    \n",
        "epochs = 100\n",
        "lossfn_cls = nn.BCELoss()\n",
        "lossfn_seg = DiceCELoss()\n",
        "# lossfn = DiceCELoss()\n",
        "metric = sklearn.metrics.f1_score\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    loss_epoch = list()\n",
        "    acc_epoch = list()\n",
        "    \n",
        "    for idx, batch in enumerate(train_loader):\n",
        "        x, y_seg, y_cls = batch['x'],batch['y_seg'],batch['y_cls'] \n",
        "        x, y_seg, y_cls = x.cuda(), y_seg.cuda(), y_cls.cuda()\n",
        "        yhat = model(x)\n",
        "        \n",
        "        if isinstance(yhat,tuple):\n",
        "            yhat_seg, yhat_cls = yhat\n",
        "            loss_seg = lossfn_seg(yhat_seg,y_seg)\n",
        "            loss = lossfn_cls(yhat_cls,y_cls) + loss_seg\n",
        "            acc = metric(y_cls.cpu().detach().numpy().flatten(),yhat_cls.cpu().detach().numpy().flatten().round()) \n",
        "        else:\n",
        "            loss = lossfn_cls(yhat,y_cls)\n",
        "            acc = metric(y_cls.cpu().detach().numpy().flatten(),yhat.cpu().detach().numpy().flatten().round()) \n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_epoch.append(loss.cpu().detach().numpy())\n",
        "        acc_epoch.append(acc)\n",
        "        \n",
        "    return np.mean(loss_epoch), np.mean(acc_epoch)\n",
        "\n",
        "def valid():\n",
        "    model.eval()\n",
        "    loss_epoch = list()\n",
        "    acc_epoch = list()\n",
        "    \n",
        "    for idx, batch in enumerate(valid_loader):\n",
        "        x, y_seg, y_cls = batch['x'],batch['y_seg'],batch['y_cls'] \n",
        "        x, y_seg, y_cls = x.cuda(), y_seg.cuda(), y_cls.cuda()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            yhat = model(x)\n",
        "            if isinstance(yhat,tuple):\n",
        "                yhat_seg, yhat_cls = yhat\n",
        "                loss_seg = lossfn_seg(yhat_seg,y_seg)\n",
        "                loss = lossfn_cls(yhat_cls,y_cls) + loss_seg\n",
        "                acc = metric(y_cls.cpu().detach().numpy().flatten(),yhat_cls.cpu().detach().numpy().flatten().round()) \n",
        "            else:\n",
        "                loss = lossfn_cls(yhat,y_cls)\n",
        "                acc = metric(y_cls.cpu().detach().numpy().flatten(),yhat.cpu().detach().numpy().flatten().round()) \n",
        "            \n",
        "        loss_epoch.append(loss.cpu().detach().numpy())\n",
        "        acc_epoch.append(acc)\n",
        "    return np.mean(loss_epoch), np.mean(acc_epoch)\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    \n",
        "    xs = list()\n",
        "    y_segs = list()\n",
        "    y_clss = list()\n",
        "    yhat_segs = list()\n",
        "    yhat_clss = list()\n",
        "    \n",
        "    for idx, batch in tqdm.tqdm(enumerate(test_loader)):\n",
        "        x, y_seg, y_cls = batch['x'],batch['y_seg'],batch['y_cls'] \n",
        "        xs.append(x)\n",
        "        y_segs.append(y_seg)\n",
        "        y_clss.append(y_cls)\n",
        "        x, y_seg, y_cls = x.cuda(), y_seg.cuda(), y_cls.cuda()\n",
        "        with torch.no_grad():\n",
        "            yhat = model(x)            \n",
        "            if isinstance(yhat,tuple):\n",
        "                yhat_seg, yhat_cls = yhat\n",
        "                yhat_segs.append(yhat_seg.cpu().detach().numpy())\n",
        "                yhat_clss.append(yhat_cls.cpu().detach().numpy())\n",
        "            else:\n",
        "                yhat_clss.append(yhat.cpu().detach().numpy())\n",
        "    return {'xs':xs,'y_segs':y_segs,'y_clss':y_clss, 'yhat_segs':yhat_segs, 'yhat_clss':yhat_clss}\n",
        "    \n",
        "from livelossplot import PlotLosses\n",
        "plotlosses = PlotLosses()\n",
        "\n",
        "loss_all = list()\n",
        "acc_all = list()\n",
        "val_loss_all = list()\n",
        "val_acc_all = list()\n",
        "\n",
        "for epoch in trange(epochs):\n",
        "    loss, acc = train()\n",
        "    loss_all.append(loss)\n",
        "    acc_all.append(acc)\n",
        "    val_loss, val_acc = valid()\n",
        "    val_loss_all.append(val_loss)\n",
        "    val_acc_all.append(val_acc)\n",
        "    \n",
        "    plotlosses.update({\n",
        "        'acc': acc_all[-1],\n",
        "        'val_acc': val_acc_all[-1],\n",
        "        'loss': loss_all[-1],\n",
        "        'val_loss': val_loss_all[-1]\n",
        "    })\n",
        "    plotlosses.send()\n",
        "    \n",
        "    if epoch == 50:\n",
        "        optimizer.param_groups[0]['lr'] = 1e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX6Tfef5EF_1"
      },
      "source": [
        "# Result "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttfc9tn8EF_3"
      },
      "source": [
        "result = test()\n",
        "\n",
        "xs= result['xs']\n",
        "y_segs = result['y_segs']\n",
        "y_clss = result['y_clss']\n",
        "yhat_segs = result['yhat_segs']\n",
        "yhat_clss = result['yhat_clss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG6mEpwIEF_4"
      },
      "source": [
        "y_clss = [k.numpy()[0,0] for k in y_clss]\n",
        "yhat_clss = [k[0,0].round() for k in yhat_clss]\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_clss, yhat_clss)\n",
        "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
        "print(accuracy_score(y_clss, yhat_clss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCeX8Z0xEF_4"
      },
      "source": [
        "for idx in range(len(y_clss)):\n",
        "    print('idx: {} - GT:{} PRED:{}'.format(idx, y_clss[idx], yhat_clss[idx]))\n",
        "    visualize(\n",
        "        x=xs[idx][0], \n",
        "        y_seg=y_segs[idx][0], \n",
        "#         y_hat_segs=np.argmax(yhat_segs[idx][0],0),\n",
        "#         y_hat_segs_processed=np.argmax(yhat_segs[idx][0],0)*yhat_clss[idx].round()\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}