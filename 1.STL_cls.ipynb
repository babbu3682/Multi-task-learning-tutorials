{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VKdq8T9oEF_n",
    "outputId": "2b0e5a2f-07ce-4779-f401-f7c8a41dc9e5"
   },
   "outputs": [],
   "source": [
    "# Install required libs\n",
    "!sudo pip install -U segmentation-models-pytorch albumentations scikit-image monai livelossplot --user --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3MAK-ZuEF_q"
   },
   "outputs": [],
   "source": [
    "# !sudo pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAyRqli6EF_r"
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyPDCEXZFzqc",
    "outputId": "795098cc-b352-4cbb-e472-46bdc3768953"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/babbu3682/Multi-task-learning-tutorials.git 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gil7jRRlEUHo",
    "outputId": "cefecc80-c3b9-44a6-c037-9b738d39a987"
   },
   "outputs": [],
   "source": [
    "!cat SSIM_cls.tar.gz* | tar -zxvpf -\n",
    "!cat SSIM_seg.tar.gz* | tar -zxvpf -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t85Nx2fQEF_s",
    "outputId": "09968e41-cfb5-47bd-8e6d-4a4a85cf2bbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 16 19:28:28 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:18:00.0 Off |                  Off |\n",
      "| 71%   73C    P8    28W / 300W |      3MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000    Off  | 00000000:3B:00.0 Off |                  Off |\n",
      "|100%   93C    P2   249W / 300W |  45210MiB / 48685MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000    Off  | 00000000:86:00.0 Off |                  Off |\n",
      "| 78%   80C    P8    51W / 300W |      3MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A6000    Off  | 00000000:AF:00.0 Off |                  Off |\n",
      "| 68%   86C    P2   230W / 300W |  25408MiB / 48685MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P: 75 (22.73%) N: 255 (77.27%) Total: 330\n",
    "P: 14 (20.00%) N: 56  (80.00%) Total: 70\n",
    "P: 21 (21.00%) N: 79  (79.00%) Total: 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/sunggu/7.KOHI/Multi_task_learning_tutorials'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CN3SCwTVEF_v"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './SSIM_cls/'\n",
    "\n",
    "x_train_list = glob.glob(os.path.join(DATA_DIR, 'train/*'))\n",
    "y_train_list = glob.glob(os.path.join(DATA_DIR, 'trainannot/*'))\n",
    "\n",
    "x_valid_list = glob.glob(os.path.join(DATA_DIR, 'val/*'))\n",
    "y_valid_list = glob.glob(os.path.join(DATA_DIR, 'valannot/*'))\n",
    "\n",
    "x_test_list  = glob.glob(os.path.join(DATA_DIR, 'test/*'))\n",
    "y_test_list  = glob.glob(os.path.join(DATA_DIR, 'testannot/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./SSIM_cls/train/1.2.276.0.7230010.3.1.4.8323329.2775.1517875174.639059.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./SSIM_cls/val/1.2.276.0.7230010.3.1.4.8323329.1764.1517875169.306622.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "f0iPTFh_EF_w"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset as BaseDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Dataset Class\n",
    "class Dataset(BaseDataset):    \n",
    "    def __init__(self, images_list, labels_list, transform):\n",
    "        self.images_list  = images_list\n",
    "        self.labels_list  = labels_list\n",
    "        self.transform    = transform\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # read data\n",
    "        image = cv2.imread(self.images_list[i], cv2.IMREAD_GRAYSCALE)\n",
    "        label = np.load(self.labels_list[i])\n",
    "        path  = self.images_list[i]\n",
    "\n",
    "        # apply transform\n",
    "        image = self.transform(image=image)['image']\n",
    "\n",
    "        return image, label, path\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import albumentations as albu\n",
    "\n",
    "\n",
    "def minmax_normalize(image, **kwargs):\n",
    "    if len(np.unique(image)) != 1:  # Sometimes it cause the nan inputs...\n",
    "        image = image.astype('float32')\n",
    "        image -= image.min()\n",
    "        image /= image.max() \n",
    "    return image\n",
    "\n",
    "\n",
    "train_transform = albu.Compose([\n",
    "    albu.HorizontalFlip(p=0.5),\n",
    "    albu.ShiftScaleRotate(scale_limit=0.10, shift_limit=0.10, rotate_limit=15, p=0.5),\n",
    "    albu.GaussNoise(p=0.2),\n",
    "    albu.OneOf(\n",
    "        [\n",
    "            albu.CLAHE(p=1),\n",
    "            albu.RandomBrightnessContrast(p=1),\n",
    "            albu.RandomGamma(p=1),\n",
    "        ],\n",
    "        p=0.3,\n",
    "    ),\n",
    "    albu.OneOf(\n",
    "        [\n",
    "            albu.Blur(blur_limit=3, p=1),\n",
    "            albu.MotionBlur(blur_limit=3, p=1),\n",
    "        ],\n",
    "        p=0.3,\n",
    "    ),\n",
    "    albu.Lambda(image=minmax_normalize, always_apply=True),\n",
    "    ToTensorV2(),    \n",
    "])\n",
    "\n",
    "valid_transform = albu.Compose([        \n",
    "    albu.Lambda(image=minmax_normalize, always_apply=True),\n",
    "    ToTensorV2(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset(images_list=x_train_list, labels_list=y_train_list, transform=train_transform)\n",
    "dataset_valid = Dataset(images_list=x_valid_list, labels_list=y_valid_list, transform=valid_transform)\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=10, num_workers=4, shuffle=True, pin_memory=True, drop_last=True)\n",
    "data_loader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=1,  num_workers=4, shuffle=True, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visulize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "cdMO4sJyEF_z",
    "outputId": "503b9008-e50a-41e5-bf09-ce4576d83d5f"
   },
   "outputs": [],
   "source": [
    "# # same image with different random transforms\n",
    "\n",
    "# batch = next(iter(train_loader))\n",
    "# x = batch['x'][0]\n",
    "# y_seg = batch['y_seg'][0]\n",
    "# y_cls = batch['y_cls'][0]\n",
    "\n",
    "# print(x.shape,y_seg.shape,data_loader_train.shape)\n",
    "# print(torch.unique(y_seg),y_cls)\n",
    "# visualize(image=x, mask=y_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Learnable Params: 11170753\n"
     ]
    }
   ],
   "source": [
    "from arch.smart_net import *\n",
    "from losses import MTL_Loss\n",
    "\n",
    "# Model\n",
    "model        = STL_1_Net(encoder_name='resnet18').to('cuda')\n",
    "# Loss\n",
    "criterion    = MTL_Loss(name='STL_CLS')\n",
    "\n",
    "# Optimizer & LR Schedule   \n",
    "optimizer    = torch.optim.AdamW(params=model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=5e-4, amsgrad=False)\n",
    "\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('Number of Learnable Params:', n_parameters)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "id": "ojQz_ZNgEF_0",
    "outputId": "ca6fe927-248f-42af-e694-b2b740f286e4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 0/80]  eta: 0:00:47  lr: 0.000100  loss: 0.7343 (0.7343)  CLS_Loss: 0.7343 (0.7343)  time: 0.5990  data: 0.4865  max mem: 1157\n",
      "Epoch: [0]  [10/80]  eta: 0:00:06  lr: 0.000100  loss: 0.5632 (0.6660)  CLS_Loss: 0.5632 (0.6660)  time: 0.0885  data: 0.0444  max mem: 1288\n",
      "Epoch: [0]  [20/80]  eta: 0:00:03  lr: 0.000100  loss: 0.5956 (0.7238)  CLS_Loss: 0.5956 (0.7238)  time: 0.0380  data: 0.0001  max mem: 1288\n",
      "Epoch: [0]  [30/80]  eta: 0:00:02  lr: 0.000100  loss: 0.6437 (0.7090)  CLS_Loss: 0.6437 (0.7090)  time: 0.0386  data: 0.0001  max mem: 1288\n",
      "Epoch: [0]  [40/80]  eta: 0:00:02  lr: 0.000100  loss: 0.5757 (0.6602)  CLS_Loss: 0.5757 (0.6602)  time: 0.0385  data: 0.0001  max mem: 1288\n",
      "Epoch: [0]  [50/80]  eta: 0:00:01  lr: 0.000100  loss: 0.5803 (0.6484)  CLS_Loss: 0.5803 (0.6484)  time: 0.0385  data: 0.0001  max mem: 1288\n",
      "Epoch: [0]  [60/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5803 (0.6448)  CLS_Loss: 0.5803 (0.6448)  time: 0.0390  data: 0.0001  max mem: 1288\n",
      "Epoch: [0]  [70/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5099 (0.6298)  CLS_Loss: 0.5099 (0.6298)  time: 0.0391  data: 0.0002  max mem: 1288\n",
      "Epoch: [0]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5099 (0.6280)  CLS_Loss: 0.5099 (0.6280)  time: 0.0387  data: 0.0001  max mem: 1288\n",
      "Epoch: [0] Total time: 0:00:03 (0.0479 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.6279711, 'CLS_Loss': 0.6279711}\n",
      "Valid:  [  0/100]  eta: 0:00:35  loss: 1.7417 (1.7417)  CLS_Loss: 1.7417 (1.7417)  time: 0.3594  data: 0.3460  max mem: 1288\n",
      "Valid:  [ 10/100]  eta: 0:00:03  loss: 0.1291 (0.6534)  CLS_Loss: 0.1291 (0.6534)  time: 0.0392  data: 0.0316  max mem: 1288\n",
      "Valid:  [ 20/100]  eta: 0:00:01  loss: 0.1206 (0.6124)  CLS_Loss: 0.1206 (0.6124)  time: 0.0070  data: 0.0001  max mem: 1288\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.1020 (0.5966)  CLS_Loss: 0.1020 (0.5966)  time: 0.0069  data: 0.0001  max mem: 1288\n",
      "Valid:  [ 40/100]  eta: 0:00:00  loss: 0.1020 (0.5634)  CLS_Loss: 0.1020 (0.5634)  time: 0.0065  data: 0.0001  max mem: 1288\n",
      "Valid:  [ 50/100]  eta: 0:00:00  loss: 0.0880 (0.5598)  CLS_Loss: 0.0880 (0.5598)  time: 0.0060  data: 0.0001  max mem: 1288\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.0894 (0.5116)  CLS_Loss: 0.0894 (0.5116)  time: 0.0060  data: 0.0001  max mem: 1288\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.1179 (0.5200)  CLS_Loss: 0.1179 (0.5200)  time: 0.0060  data: 0.0001  max mem: 1288\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.1375 (0.5709)  CLS_Loss: 0.1375 (0.5709)  time: 0.0060  data: 0.0001  max mem: 1288\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.1293 (0.5188)  CLS_Loss: 0.1293 (0.5188)  time: 0.0059  data: 0.0001  max mem: 1288\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.0984 (0.5922)  CLS_Loss: 0.0984 (0.5922)  time: 0.0057  data: 0.0001  max mem: 1288\n",
      "Valid: Total time: 0:00:01 (0.0113 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.5921701, 'CLS_Loss': 0.5921701, 'auc': 0.6694079, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [1]  [ 0/80]  eta: 0:00:33  lr: 0.000100  loss: 1.1733 (1.1733)  CLS_Loss: 1.1733 (1.1733)  time: 0.4206  data: 0.3861  max mem: 1387\n",
      "Epoch: [1]  [10/80]  eta: 0:00:05  lr: 0.000100  loss: 0.6555 (0.6966)  CLS_Loss: 0.6555 (0.6966)  time: 0.0735  data: 0.0353  max mem: 1387\n",
      "Epoch: [1]  [20/80]  eta: 0:00:03  lr: 0.000100  loss: 0.5476 (0.6197)  CLS_Loss: 0.5476 (0.6197)  time: 0.0386  data: 0.0002  max mem: 1387\n",
      "Epoch: [1]  [30/80]  eta: 0:00:02  lr: 0.000100  loss: 0.5357 (0.6034)  CLS_Loss: 0.5357 (0.6034)  time: 0.0386  data: 0.0001  max mem: 1387\n",
      "Epoch: [1]  [40/80]  eta: 0:00:01  lr: 0.000100  loss: 0.6044 (0.6433)  CLS_Loss: 0.6044 (0.6433)  time: 0.0391  data: 0.0001  max mem: 1387\n",
      "Epoch: [1]  [50/80]  eta: 0:00:01  lr: 0.000100  loss: 0.5181 (0.6195)  CLS_Loss: 0.5181 (0.6195)  time: 0.0389  data: 0.0001  max mem: 1387\n",
      "Epoch: [1]  [60/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4438 (0.5913)  CLS_Loss: 0.4438 (0.5913)  time: 0.0389  data: 0.0001  max mem: 1387\n",
      "Epoch: [1]  [70/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4371 (0.5816)  CLS_Loss: 0.4371 (0.5816)  time: 0.0392  data: 0.0001  max mem: 1387\n",
      "Epoch: [1]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5009 (0.5761)  CLS_Loss: 0.5009 (0.5761)  time: 0.0387  data: 0.0001  max mem: 1387\n",
      "Epoch: [1] Total time: 0:00:03 (0.0456 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.5760655, 'CLS_Loss': 0.5760655}\n",
      "Valid:  [  0/100]  eta: 0:00:36  loss: 2.6597 (2.6597)  CLS_Loss: 2.6597 (2.6597)  time: 0.3670  data: 0.3551  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:03  loss: 0.1352 (0.9832)  CLS_Loss: 0.1352 (0.9832)  time: 0.0395  data: 0.0323  max mem: 1387\n",
      "Valid:  [ 20/100]  eta: 0:00:01  loss: 0.1245 (1.0201)  CLS_Loss: 0.1245 (1.0201)  time: 0.0068  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.0987 (0.8654)  CLS_Loss: 0.0987 (0.8654)  time: 0.0069  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:00  loss: 0.0918 (0.7720)  CLS_Loss: 0.0918 (0.7720)  time: 0.0066  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:00  loss: 0.0916 (0.8387)  CLS_Loss: 0.0916 (0.8387)  time: 0.0061  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.1041 (0.8469)  CLS_Loss: 0.1041 (0.8469)  time: 0.0060  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.0793 (0.7396)  CLS_Loss: 0.0793 (0.7396)  time: 0.0060  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.0923 (0.6920)  CLS_Loss: 0.0923 (0.6920)  time: 0.0060  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.0923 (0.6746)  CLS_Loss: 0.0923 (0.6746)  time: 0.0060  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.0977 (0.6698)  CLS_Loss: 0.0977 (0.6698)  time: 0.0057  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:01 (0.0111 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.6698249, 'CLS_Loss': 0.6698249, 'auc': 0.5800439, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [2]  [ 0/80]  eta: 0:00:36  lr: 0.000100  loss: 0.5148 (0.5148)  CLS_Loss: 0.5148 (0.5148)  time: 0.4601  data: 0.4332  max mem: 1387\n",
      "Epoch: [2]  [10/80]  eta: 0:00:05  lr: 0.000100  loss: 0.6087 (0.5830)  CLS_Loss: 0.6087 (0.5830)  time: 0.0777  data: 0.0395  max mem: 1387\n",
      "Epoch: [2]  [20/80]  eta: 0:00:03  lr: 0.000100  loss: 0.5289 (0.5545)  CLS_Loss: 0.5289 (0.5545)  time: 0.0393  data: 0.0001  max mem: 1387\n",
      "Epoch: [2]  [30/80]  eta: 0:00:02  lr: 0.000100  loss: 0.5071 (0.5502)  CLS_Loss: 0.5071 (0.5502)  time: 0.0389  data: 0.0001  max mem: 1387\n",
      "Epoch: [2]  [40/80]  eta: 0:00:01  lr: 0.000100  loss: 0.5170 (0.5415)  CLS_Loss: 0.5170 (0.5415)  time: 0.0386  data: 0.0001  max mem: 1387\n",
      "Epoch: [2]  [50/80]  eta: 0:00:01  lr: 0.000100  loss: 0.6014 (0.5852)  CLS_Loss: 0.6014 (0.5852)  time: 0.0386  data: 0.0001  max mem: 1387\n",
      "Epoch: [2]  [60/80]  eta: 0:00:00  lr: 0.000100  loss: 0.6046 (0.5941)  CLS_Loss: 0.6046 (0.5941)  time: 0.0391  data: 0.0001  max mem: 1387\n",
      "Epoch: [2]  [70/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5227 (0.5809)  CLS_Loss: 0.5227 (0.5809)  time: 0.0392  data: 0.0001  max mem: 1387\n",
      "Epoch: [2]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4952 (0.5757)  CLS_Loss: 0.4952 (0.5757)  time: 0.0389  data: 0.0001  max mem: 1387\n",
      "Epoch: [2] Total time: 0:00:03 (0.0458 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.5757366, 'CLS_Loss': 0.5757366}\n",
      "Valid:  [  0/100]  eta: 0:00:36  loss: 0.3010 (0.3010)  CLS_Loss: 0.3010 (0.3010)  time: 0.3612  data: 0.3480  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:03  loss: 0.3285 (0.8581)  CLS_Loss: 0.3285 (0.8581)  time: 0.0395  data: 0.0317  max mem: 1387\n",
      "Valid:  [ 20/100]  eta: 0:00:01  loss: 0.2665 (0.6653)  CLS_Loss: 0.2665 (0.6653)  time: 0.0073  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.2223 (0.6190)  CLS_Loss: 0.2223 (0.6190)  time: 0.0071  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:00  loss: 0.2434 (0.6862)  CLS_Loss: 0.2434 (0.6862)  time: 0.0066  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:00  loss: 0.2846 (0.6277)  CLS_Loss: 0.2846 (0.6277)  time: 0.0063  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.2692 (0.6207)  CLS_Loss: 0.2692 (0.6207)  time: 0.0072  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.2017 (0.5557)  CLS_Loss: 0.2017 (0.5557)  time: 0.0071  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.1813 (0.5411)  CLS_Loss: 0.1813 (0.5411)  time: 0.0061  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.1813 (0.5446)  CLS_Loss: 0.1813 (0.5446)  time: 0.0059  data: 0.0001  max mem: 1387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.1578 (0.5418)  CLS_Loss: 0.1578 (0.5418)  time: 0.0057  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:01 (0.0114 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.5417567, 'CLS_Loss': 0.5417567, 'auc': 0.6365132, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [3]  [ 0/80]  eta: 0:00:34  lr: 0.000100  loss: 0.5023 (0.5023)  CLS_Loss: 0.5023 (0.5023)  time: 0.4252  data: 0.3909  max mem: 1387\n",
      "Epoch: [3]  [10/80]  eta: 0:00:05  lr: 0.000100  loss: 0.4382 (0.4455)  CLS_Loss: 0.4382 (0.4455)  time: 0.0739  data: 0.0357  max mem: 1387\n",
      "Epoch: [3]  [20/80]  eta: 0:00:03  lr: 0.000100  loss: 0.4382 (0.4984)  CLS_Loss: 0.4382 (0.4984)  time: 0.0387  data: 0.0001  max mem: 1387\n",
      "Epoch: [3]  [30/80]  eta: 0:00:02  lr: 0.000100  loss: 0.4694 (0.5253)  CLS_Loss: 0.4694 (0.5253)  time: 0.0390  data: 0.0001  max mem: 1387\n",
      "Epoch: [3]  [40/80]  eta: 0:00:01  lr: 0.000100  loss: 0.5447 (0.5340)  CLS_Loss: 0.5447 (0.5340)  time: 0.0391  data: 0.0001  max mem: 1387\n",
      "Epoch: [3]  [50/80]  eta: 0:00:01  lr: 0.000100  loss: 0.5333 (0.5327)  CLS_Loss: 0.5333 (0.5327)  time: 0.0391  data: 0.0001  max mem: 1387\n",
      "Epoch: [3]  [60/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5624 (0.5430)  CLS_Loss: 0.5624 (0.5430)  time: 0.0393  data: 0.0001  max mem: 1387\n",
      "Epoch: [3]  [70/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4884 (0.5376)  CLS_Loss: 0.4884 (0.5376)  time: 0.0397  data: 0.0001  max mem: 1387\n",
      "Epoch: [3]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4884 (0.5436)  CLS_Loss: 0.4884 (0.5436)  time: 0.0403  data: 0.0001  max mem: 1387\n",
      "Epoch: [3] Total time: 0:00:03 (0.0461 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.543563, 'CLS_Loss': 0.543563}\n",
      "Valid:  [  0/100]  eta: 0:00:36  loss: 0.2198 (0.2198)  CLS_Loss: 0.2198 (0.2198)  time: 0.3666  data: 0.3515  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:03  loss: 0.1819 (0.4110)  CLS_Loss: 0.1819 (0.4110)  time: 0.0404  data: 0.0321  max mem: 1387\n",
      "Valid:  [ 20/100]  eta: 0:00:01  loss: 0.1398 (0.5404)  CLS_Loss: 0.1398 (0.5404)  time: 0.0077  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.1428 (0.4570)  CLS_Loss: 0.1428 (0.4570)  time: 0.0075  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:00  loss: 0.1372 (0.4121)  CLS_Loss: 0.1372 (0.4121)  time: 0.0070  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:00  loss: 0.1564 (0.4748)  CLS_Loss: 0.1564 (0.4748)  time: 0.0065  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.1852 (0.5061)  CLS_Loss: 0.1852 (0.5061)  time: 0.0064  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.2044 (0.5604)  CLS_Loss: 0.2044 (0.5604)  time: 0.0064  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.1806 (0.5482)  CLS_Loss: 0.1806 (0.5482)  time: 0.0067  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.1682 (0.5044)  CLS_Loss: 0.1682 (0.5044)  time: 0.0065  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.1752 (0.5475)  CLS_Loss: 0.1752 (0.5475)  time: 0.0062  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:01 (0.0119 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.5475398, 'CLS_Loss': 0.5475398, 'auc': 0.6902412, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [4]  [ 0/80]  eta: 0:00:34  lr: 0.000100  loss: 0.6756 (0.6756)  CLS_Loss: 0.6756 (0.6756)  time: 0.4371  data: 0.4038  max mem: 1387\n",
      "Epoch: [4]  [10/80]  eta: 0:00:05  lr: 0.000100  loss: 0.4684 (0.4855)  CLS_Loss: 0.4684 (0.4855)  time: 0.0769  data: 0.0369  max mem: 1387\n",
      "Epoch: [4]  [20/80]  eta: 0:00:03  lr: 0.000100  loss: 0.5002 (0.5218)  CLS_Loss: 0.5002 (0.5218)  time: 0.0415  data: 0.0002  max mem: 1387\n",
      "Epoch: [4]  [30/80]  eta: 0:00:02  lr: 0.000100  loss: 0.5703 (0.5499)  CLS_Loss: 0.5703 (0.5499)  time: 0.0416  data: 0.0001  max mem: 1387\n",
      "Epoch: [4]  [40/80]  eta: 0:00:02  lr: 0.000100  loss: 0.5049 (0.5506)  CLS_Loss: 0.5049 (0.5506)  time: 0.0415  data: 0.0001  max mem: 1387\n",
      "Epoch: [4]  [50/80]  eta: 0:00:01  lr: 0.000100  loss: 0.4482 (0.5464)  CLS_Loss: 0.4482 (0.5464)  time: 0.0422  data: 0.0001  max mem: 1387\n",
      "Epoch: [4]  [60/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4658 (0.5362)  CLS_Loss: 0.4658 (0.5362)  time: 0.0413  data: 0.0002  max mem: 1387\n",
      "Epoch: [4]  [70/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4665 (0.5442)  CLS_Loss: 0.4665 (0.5442)  time: 0.0472  data: 0.0002  max mem: 1387\n",
      "Epoch: [4]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5126 (0.5466)  CLS_Loss: 0.5126 (0.5466)  time: 0.0669  data: 0.0001  max mem: 1387\n",
      "Epoch: [4] Total time: 0:00:04 (0.0554 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.546639, 'CLS_Loss': 0.546639}\n",
      "Valid:  [  0/100]  eta: 0:00:38  loss: 0.1866 (0.1866)  CLS_Loss: 0.1866 (0.1866)  time: 0.3810  data: 0.3659  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:03  loss: 0.2028 (0.5564)  CLS_Loss: 0.2028 (0.5564)  time: 0.0442  data: 0.0334  max mem: 1387\n",
      "Valid:  [ 20/100]  eta: 0:00:02  loss: 0.2176 (0.3959)  CLS_Loss: 0.2176 (0.3959)  time: 0.0106  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.2104 (0.3862)  CLS_Loss: 0.2104 (0.3862)  time: 0.0106  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:01  loss: 0.2353 (0.4220)  CLS_Loss: 0.2353 (0.4220)  time: 0.0108  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:00  loss: 0.3338 (0.4673)  CLS_Loss: 0.3338 (0.4673)  time: 0.0108  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.3338 (0.4979)  CLS_Loss: 0.3338 (0.4979)  time: 0.0102  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.2194 (0.4942)  CLS_Loss: 0.2194 (0.4942)  time: 0.0099  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.2194 (0.4921)  CLS_Loss: 0.2194 (0.4921)  time: 0.0103  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.2886 (0.5113)  CLS_Loss: 0.2886 (0.5113)  time: 0.0106  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.2213 (0.5254)  CLS_Loss: 0.2213 (0.5254)  time: 0.0106  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:01 (0.0156 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.5254152, 'CLS_Loss': 0.5254152, 'auc': 0.6633772, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [5]  [ 0/80]  eta: 0:00:37  lr: 0.000100  loss: 0.5039 (0.5039)  CLS_Loss: 0.5039 (0.5039)  time: 0.4626  data: 0.4226  max mem: 1387\n",
      "Epoch: [5]  [10/80]  eta: 0:00:06  lr: 0.000100  loss: 0.5439 (0.6083)  CLS_Loss: 0.5439 (0.6083)  time: 0.0923  data: 0.0385  max mem: 1387\n",
      "Epoch: [5]  [20/80]  eta: 0:00:04  lr: 0.000100  loss: 0.5265 (0.5650)  CLS_Loss: 0.5265 (0.5650)  time: 0.0551  data: 0.0001  max mem: 1387\n",
      "Epoch: [5]  [30/80]  eta: 0:00:03  lr: 0.000100  loss: 0.4787 (0.5490)  CLS_Loss: 0.4787 (0.5490)  time: 0.0476  data: 0.0001  max mem: 1387\n",
      "Epoch: [5]  [40/80]  eta: 0:00:02  lr: 0.000100  loss: 0.4859 (0.5467)  CLS_Loss: 0.4859 (0.5467)  time: 0.0406  data: 0.0001  max mem: 1387\n",
      "Epoch: [5]  [50/80]  eta: 0:00:01  lr: 0.000100  loss: 0.5307 (0.5564)  CLS_Loss: 0.5307 (0.5564)  time: 0.0405  data: 0.0002  max mem: 1387\n",
      "Epoch: [5]  [60/80]  eta: 0:00:01  lr: 0.000100  loss: 0.5409 (0.5475)  CLS_Loss: 0.5409 (0.5475)  time: 0.0410  data: 0.0002  max mem: 1387\n",
      "Epoch: [5]  [70/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4242 (0.5373)  CLS_Loss: 0.4242 (0.5373)  time: 0.0421  data: 0.0002  max mem: 1387\n",
      "Epoch: [5]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4676 (0.5459)  CLS_Loss: 0.4676 (0.5459)  time: 0.0474  data: 0.0002  max mem: 1387\n",
      "Epoch: [5] Total time: 0:00:04 (0.0538 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.5458516, 'CLS_Loss': 0.5458516}\n",
      "Valid:  [  0/100]  eta: 0:00:36  loss: 0.1160 (0.1160)  CLS_Loss: 0.1160 (0.1160)  time: 0.3653  data: 0.3497  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:04  loss: 0.1015 (0.4252)  CLS_Loss: 0.1015 (0.4252)  time: 0.0450  data: 0.0319  max mem: 1387\n",
      "Valid:  [ 20/100]  eta: 0:00:02  loss: 0.1477 (0.7877)  CLS_Loss: 0.1477 (0.7877)  time: 0.0124  data: 0.0002  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.2169 (0.7000)  CLS_Loss: 0.2169 (0.7000)  time: 0.0112  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:01  loss: 0.1548 (0.5938)  CLS_Loss: 0.1548 (0.5938)  time: 0.0106  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:00  loss: 0.1612 (0.5723)  CLS_Loss: 0.1612 (0.5723)  time: 0.0106  data: 0.0001  max mem: 1387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.1936 (0.6383)  CLS_Loss: 0.1936 (0.6383)  time: 0.0107  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.1548 (0.5717)  CLS_Loss: 0.1548 (0.5717)  time: 0.0109  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.1567 (0.5961)  CLS_Loss: 0.1567 (0.5961)  time: 0.0108  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.1812 (0.5939)  CLS_Loss: 0.1812 (0.5939)  time: 0.0106  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.2101 (0.5780)  CLS_Loss: 0.2101 (0.5780)  time: 0.0105  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:01 (0.0160 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.5779929, 'CLS_Loss': 0.5779929, 'auc': 0.6315789, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [6]  [ 0/80]  eta: 0:00:35  lr: 0.000100  loss: 0.2102 (0.2102)  CLS_Loss: 0.2102 (0.2102)  time: 0.4437  data: 0.4075  max mem: 1387\n",
      "Epoch: [6]  [10/80]  eta: 0:00:06  lr: 0.000100  loss: 0.4520 (0.4540)  CLS_Loss: 0.4520 (0.4540)  time: 0.0931  data: 0.0372  max mem: 1387\n",
      "Epoch: [6]  [20/80]  eta: 0:00:04  lr: 0.000100  loss: 0.4569 (0.4960)  CLS_Loss: 0.4569 (0.4960)  time: 0.0525  data: 0.0002  max mem: 1387\n",
      "Epoch: [6]  [30/80]  eta: 0:00:03  lr: 0.000100  loss: 0.5555 (0.5301)  CLS_Loss: 0.5555 (0.5301)  time: 0.0455  data: 0.0002  max mem: 1387\n",
      "Epoch: [6]  [40/80]  eta: 0:00:02  lr: 0.000100  loss: 0.5379 (0.5314)  CLS_Loss: 0.5379 (0.5314)  time: 0.0431  data: 0.0002  max mem: 1387\n",
      "Epoch: [6]  [50/80]  eta: 0:00:01  lr: 0.000100  loss: 0.4382 (0.5031)  CLS_Loss: 0.4382 (0.5031)  time: 0.0429  data: 0.0002  max mem: 1387\n",
      "Epoch: [6]  [60/80]  eta: 0:00:01  lr: 0.000100  loss: 0.4295 (0.5373)  CLS_Loss: 0.4295 (0.5373)  time: 0.0431  data: 0.0002  max mem: 1387\n",
      "Epoch: [6]  [70/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5709 (0.5403)  CLS_Loss: 0.5709 (0.5403)  time: 0.0492  data: 0.0002  max mem: 1387\n",
      "Epoch: [6]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5754 (0.5522)  CLS_Loss: 0.5754 (0.5522)  time: 0.0693  data: 0.0001  max mem: 1387\n",
      "Epoch: [6] Total time: 0:00:04 (0.0595 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.5521746, 'CLS_Loss': 0.5521746}\n",
      "Valid:  [  0/100]  eta: 0:00:37  loss: 0.3423 (0.3423)  CLS_Loss: 0.3423 (0.3423)  time: 0.3754  data: 0.3590  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:04  loss: 0.3154 (0.5346)  CLS_Loss: 0.3154 (0.5346)  time: 0.0460  data: 0.0328  max mem: 1387\n",
      "Valid:  [ 20/100]  eta: 0:00:02  loss: 0.2595 (0.5776)  CLS_Loss: 0.2595 (0.5776)  time: 0.0122  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.2595 (0.6111)  CLS_Loss: 0.2595 (0.6111)  time: 0.0108  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:01  loss: 0.1906 (0.5302)  CLS_Loss: 0.1906 (0.5302)  time: 0.0099  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:00  loss: 0.1906 (0.5483)  CLS_Loss: 0.1906 (0.5483)  time: 0.0101  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.3474 (0.5568)  CLS_Loss: 0.3474 (0.5568)  time: 0.0140  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.2647 (0.5545)  CLS_Loss: 0.2647 (0.5545)  time: 0.0171  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.2507 (0.5444)  CLS_Loss: 0.2507 (0.5444)  time: 0.0164  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.2249 (0.5318)  CLS_Loss: 0.2249 (0.5318)  time: 0.0161  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.2003 (0.5140)  CLS_Loss: 0.2003 (0.5140)  time: 0.0160  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:01 (0.0193 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.513985, 'CLS_Loss': 0.513985, 'auc': 0.7072368, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [7]  [ 0/80]  eta: 0:00:40  lr: 0.000100  loss: 0.4856 (0.4856)  CLS_Loss: 0.4856 (0.4856)  time: 0.5037  data: 0.4391  max mem: 1387\n",
      "Epoch: [7]  [10/80]  eta: 0:00:11  lr: 0.000100  loss: 0.4856 (0.4738)  CLS_Loss: 0.4856 (0.4738)  time: 0.1671  data: 0.0400  max mem: 1387\n",
      "Epoch: [7]  [20/80]  eta: 0:00:08  lr: 0.000100  loss: 0.4859 (0.4993)  CLS_Loss: 0.4859 (0.4993)  time: 0.1199  data: 0.0001  max mem: 1387\n",
      "Epoch: [7]  [30/80]  eta: 0:00:06  lr: 0.000100  loss: 0.4345 (0.4825)  CLS_Loss: 0.4345 (0.4825)  time: 0.1085  data: 0.0002  max mem: 1387\n",
      "Epoch: [7]  [40/80]  eta: 0:00:04  lr: 0.000100  loss: 0.4323 (0.4900)  CLS_Loss: 0.4323 (0.4900)  time: 0.0997  data: 0.0002  max mem: 1387\n",
      "Epoch: [7]  [50/80]  eta: 0:00:03  lr: 0.000100  loss: 0.5473 (0.5164)  CLS_Loss: 0.5473 (0.5164)  time: 0.0857  data: 0.0001  max mem: 1387\n",
      "Epoch: [7]  [60/80]  eta: 0:00:02  lr: 0.000100  loss: 0.5538 (0.5179)  CLS_Loss: 0.5538 (0.5179)  time: 0.0610  data: 0.0002  max mem: 1387\n",
      "Epoch: [7]  [70/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5367 (0.5176)  CLS_Loss: 0.5367 (0.5176)  time: 0.0455  data: 0.0002  max mem: 1387\n",
      "Epoch: [7]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5367 (0.5236)  CLS_Loss: 0.5367 (0.5236)  time: 0.0742  data: 0.0001  max mem: 1387\n",
      "Epoch: [7] Total time: 0:00:07 (0.0965 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.5235901, 'CLS_Loss': 0.5235901}\n",
      "Valid:  [  0/100]  eta: 0:00:35  loss: 0.0989 (0.0989)  CLS_Loss: 0.0989 (0.0989)  time: 0.3540  data: 0.3400  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:03  loss: 1.3328 (1.0074)  CLS_Loss: 1.3328 (1.0074)  time: 0.0422  data: 0.0310  max mem: 1387\n",
      "Valid:  [ 20/100]  eta: 0:00:02  loss: 0.1932 (0.6572)  CLS_Loss: 0.1932 (0.6572)  time: 0.0106  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.1641 (0.5827)  CLS_Loss: 0.1641 (0.5827)  time: 0.0106  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:01  loss: 0.1867 (0.5307)  CLS_Loss: 0.1867 (0.5307)  time: 0.0113  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:00  loss: 0.1846 (0.5478)  CLS_Loss: 0.1846 (0.5478)  time: 0.0117  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.1654 (0.4856)  CLS_Loss: 0.1654 (0.4856)  time: 0.0119  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.1916 (0.5101)  CLS_Loss: 0.1916 (0.5101)  time: 0.0115  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.2261 (0.5381)  CLS_Loss: 0.2261 (0.5381)  time: 0.0127  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.2280 (0.5395)  CLS_Loss: 0.2280 (0.5395)  time: 0.0133  data: 0.0002  max mem: 1387\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.2211 (0.5228)  CLS_Loss: 0.2211 (0.5228)  time: 0.0116  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:01 (0.0170 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.5227762, 'CLS_Loss': 0.5227762, 'auc': 0.7121711, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [8]  [ 0/80]  eta: 0:00:40  lr: 0.000100  loss: 0.5211 (0.5211)  CLS_Loss: 0.5211 (0.5211)  time: 0.5028  data: 0.4531  max mem: 1387\n",
      "Epoch: [8]  [10/80]  eta: 0:00:08  lr: 0.000100  loss: 0.5211 (0.5230)  CLS_Loss: 0.5211 (0.5230)  time: 0.1248  data: 0.0414  max mem: 1387\n",
      "Epoch: [8]  [20/80]  eta: 0:00:06  lr: 0.000100  loss: 0.5336 (0.5396)  CLS_Loss: 0.5336 (0.5396)  time: 0.0865  data: 0.0002  max mem: 1387\n",
      "Epoch: [8]  [30/80]  eta: 0:00:05  lr: 0.000100  loss: 0.5712 (0.5552)  CLS_Loss: 0.5712 (0.5552)  time: 0.0997  data: 0.0002  max mem: 1387\n",
      "Epoch: [8]  [40/80]  eta: 0:00:04  lr: 0.000100  loss: 0.5712 (0.5784)  CLS_Loss: 0.5712 (0.5784)  time: 0.1229  data: 0.0002  max mem: 1387\n",
      "Epoch: [8]  [50/80]  eta: 0:00:03  lr: 0.000100  loss: 0.4587 (0.5592)  CLS_Loss: 0.4587 (0.5592)  time: 0.1230  data: 0.0002  max mem: 1387\n",
      "Epoch: [8]  [60/80]  eta: 0:00:02  lr: 0.000100  loss: 0.4576 (0.5528)  CLS_Loss: 0.4576 (0.5528)  time: 0.1053  data: 0.0001  max mem: 1387\n",
      "Epoch: [8]  [70/80]  eta: 0:00:01  lr: 0.000100  loss: 0.4642 (0.5378)  CLS_Loss: 0.4642 (0.5378)  time: 0.0998  data: 0.0001  max mem: 1387\n",
      "Epoch: [8]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4642 (0.5375)  CLS_Loss: 0.4642 (0.5375)  time: 0.0969  data: 0.0001  max mem: 1387\n",
      "Epoch: [8] Total time: 0:00:08 (0.1103 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.5374724, 'CLS_Loss': 0.5374724}\n",
      "Valid:  [  0/100]  eta: 0:00:33  loss: 0.1666 (0.1666)  CLS_Loss: 0.1666 (0.1666)  time: 0.3344  data: 0.3181  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:03  loss: 0.1666 (0.4344)  CLS_Loss: 0.1666 (0.4344)  time: 0.0400  data: 0.0290  max mem: 1387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid:  [ 20/100]  eta: 0:00:02  loss: 0.1561 (0.3735)  CLS_Loss: 0.1561 (0.3735)  time: 0.0103  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.1896 (0.5235)  CLS_Loss: 0.1896 (0.5235)  time: 0.0104  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:01  loss: 0.2253 (0.5484)  CLS_Loss: 0.2253 (0.5484)  time: 0.0105  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:00  loss: 0.1962 (0.5682)  CLS_Loss: 0.1962 (0.5682)  time: 0.0106  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.1933 (0.5081)  CLS_Loss: 0.1933 (0.5081)  time: 0.0108  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.1429 (0.5244)  CLS_Loss: 0.1429 (0.5244)  time: 0.0096  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.1588 (0.5511)  CLS_Loss: 0.1588 (0.5511)  time: 0.0075  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.2551 (0.5305)  CLS_Loss: 0.2551 (0.5305)  time: 0.0062  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.2217 (0.5087)  CLS_Loss: 0.2217 (0.5087)  time: 0.0058  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:01 (0.0136 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.5087163, 'CLS_Loss': 0.5087163, 'auc': 0.7505482, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [9]  [ 0/80]  eta: 0:00:41  lr: 0.000100  loss: 0.3946 (0.3946)  CLS_Loss: 0.3946 (0.3946)  time: 0.5207  data: 0.4710  max mem: 1387\n",
      "Epoch: [9]  [10/80]  eta: 0:00:09  lr: 0.000100  loss: 0.5101 (0.5459)  CLS_Loss: 0.5101 (0.5459)  time: 0.1376  data: 0.0430  max mem: 1387\n",
      "Epoch: [9]  [20/80]  eta: 0:00:07  lr: 0.000100  loss: 0.5101 (0.5843)  CLS_Loss: 0.5101 (0.5843)  time: 0.1134  data: 0.0001  max mem: 1387\n",
      "Epoch: [9]  [30/80]  eta: 0:00:06  lr: 0.000100  loss: 0.3896 (0.5412)  CLS_Loss: 0.3896 (0.5412)  time: 0.1277  data: 0.0001  max mem: 1387\n",
      "Epoch: [9]  [40/80]  eta: 0:00:05  lr: 0.000100  loss: 0.3896 (0.5155)  CLS_Loss: 0.3896 (0.5155)  time: 0.1249  data: 0.0001  max mem: 1387\n",
      "Epoch: [9]  [50/80]  eta: 0:00:03  lr: 0.000100  loss: 0.4254 (0.5004)  CLS_Loss: 0.4254 (0.5004)  time: 0.1062  data: 0.0001  max mem: 1387\n",
      "Epoch: [9]  [60/80]  eta: 0:00:02  lr: 0.000100  loss: 0.3926 (0.4958)  CLS_Loss: 0.3926 (0.4958)  time: 0.0948  data: 0.0001  max mem: 1387\n",
      "Epoch: [9]  [70/80]  eta: 0:00:01  lr: 0.000100  loss: 0.4464 (0.5024)  CLS_Loss: 0.4464 (0.5024)  time: 0.0968  data: 0.0001  max mem: 1387\n",
      "Epoch: [9]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4933 (0.5153)  CLS_Loss: 0.4933 (0.5153)  time: 0.0907  data: 0.0001  max mem: 1387\n",
      "Epoch: [9] Total time: 0:00:09 (0.1133 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.5152652, 'CLS_Loss': 0.5152652}\n",
      "Valid:  [  0/100]  eta: 0:00:34  loss: 0.0483 (0.0483)  CLS_Loss: 0.0483 (0.0483)  time: 0.3413  data: 0.3296  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:03  loss: 0.2845 (0.6191)  CLS_Loss: 0.2845 (0.6191)  time: 0.0366  data: 0.0300  max mem: 1387\n",
      "Valid:  [ 20/100]  eta: 0:00:01  loss: 0.2553 (0.5637)  CLS_Loss: 0.2553 (0.5637)  time: 0.0061  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.2262 (0.5432)  CLS_Loss: 0.2262 (0.5432)  time: 0.0060  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:00  loss: 0.2121 (0.5446)  CLS_Loss: 0.2121 (0.5446)  time: 0.0061  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:00  loss: 0.1757 (0.5524)  CLS_Loss: 0.1757 (0.5524)  time: 0.0061  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.2212 (0.5293)  CLS_Loss: 0.2212 (0.5293)  time: 0.0062  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.2212 (0.5745)  CLS_Loss: 0.2212 (0.5745)  time: 0.0064  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.1725 (0.5943)  CLS_Loss: 0.1725 (0.5943)  time: 0.0065  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.2151 (0.5581)  CLS_Loss: 0.2151 (0.5581)  time: 0.0065  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.2151 (0.5786)  CLS_Loss: 0.2151 (0.5786)  time: 0.0062  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:01 (0.0108 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.5785612, 'CLS_Loss': 0.5785612, 'auc': 0.6321272, 'f1': 0.0, 'acc': 0.75, 'sen': 0.0, 'spe': 0.9868421}\n",
      "Epoch: [10]  [ 0/80]  eta: 0:00:36  lr: 0.000100  loss: 0.4193 (0.4193)  CLS_Loss: 0.4193 (0.4193)  time: 0.4559  data: 0.4140  max mem: 1387\n",
      "Epoch: [10]  [10/80]  eta: 0:00:09  lr: 0.000100  loss: 0.5984 (0.5373)  CLS_Loss: 0.5984 (0.5373)  time: 0.1370  data: 0.0378  max mem: 1387\n",
      "Epoch: [10]  [20/80]  eta: 0:00:07  lr: 0.000100  loss: 0.5716 (0.5613)  CLS_Loss: 0.5716 (0.5613)  time: 0.1160  data: 0.0001  max mem: 1387\n",
      "Epoch: [10]  [30/80]  eta: 0:00:06  lr: 0.000100  loss: 0.5438 (0.5735)  CLS_Loss: 0.5438 (0.5735)  time: 0.1271  data: 0.0001  max mem: 1387\n",
      "Epoch: [10]  [40/80]  eta: 0:00:05  lr: 0.000100  loss: 0.4960 (0.5574)  CLS_Loss: 0.4960 (0.5574)  time: 0.1271  data: 0.0001  max mem: 1387\n",
      "Epoch: [10]  [50/80]  eta: 0:00:03  lr: 0.000100  loss: 0.4636 (0.5391)  CLS_Loss: 0.4636 (0.5391)  time: 0.1205  data: 0.0001  max mem: 1387\n",
      "Epoch: [10]  [60/80]  eta: 0:00:02  lr: 0.000100  loss: 0.4221 (0.5283)  CLS_Loss: 0.4221 (0.5283)  time: 0.1046  data: 0.0001  max mem: 1387\n",
      "Epoch: [10]  [70/80]  eta: 0:00:01  lr: 0.000100  loss: 0.4365 (0.5232)  CLS_Loss: 0.4365 (0.5232)  time: 0.0973  data: 0.0001  max mem: 1387\n",
      "Epoch: [10]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.3634 (0.5061)  CLS_Loss: 0.3634 (0.5061)  time: 0.0946  data: 0.0001  max mem: 1387\n",
      "Epoch: [10] Total time: 0:00:09 (0.1170 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.5060517, 'CLS_Loss': 0.5060517}\n",
      "Valid:  [  0/100]  eta: 0:00:40  loss: 0.2264 (0.2264)  CLS_Loss: 0.2264 (0.2264)  time: 0.4054  data: 0.3942  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:03  loss: 0.1838 (0.5491)  CLS_Loss: 0.1838 (0.5491)  time: 0.0424  data: 0.0360  max mem: 1387\n",
      "Valid:  [ 20/100]  eta: 0:00:01  loss: 0.1594 (0.5448)  CLS_Loss: 0.1594 (0.5448)  time: 0.0060  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.1659 (0.4706)  CLS_Loss: 0.1659 (0.4706)  time: 0.0061  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:00  loss: 0.1676 (0.5282)  CLS_Loss: 0.1676 (0.5282)  time: 0.0065  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:00  loss: 0.1931 (0.5584)  CLS_Loss: 0.1931 (0.5584)  time: 0.0067  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.1912 (0.5700)  CLS_Loss: 0.1912 (0.5700)  time: 0.0071  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.1397 (0.5133)  CLS_Loss: 0.1397 (0.5133)  time: 0.0077  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.1588 (0.5417)  CLS_Loss: 0.1588 (0.5417)  time: 0.0077  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.1977 (0.5432)  CLS_Loss: 0.1977 (0.5432)  time: 0.0074  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.1727 (0.5215)  CLS_Loss: 0.1727 (0.5215)  time: 0.0072  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:01 (0.0122 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.5215234, 'CLS_Loss': 0.5215234, 'auc': 0.7357456, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [11]  [ 0/80]  eta: 0:00:42  lr: 0.000100  loss: 0.7129 (0.7129)  CLS_Loss: 0.7129 (0.7129)  time: 0.5345  data: 0.4780  max mem: 1387\n",
      "Epoch: [11]  [10/80]  eta: 0:00:09  lr: 0.000100  loss: 0.5290 (0.5971)  CLS_Loss: 0.5290 (0.5971)  time: 0.1346  data: 0.0436  max mem: 1387\n",
      "Epoch: [11]  [20/80]  eta: 0:00:07  lr: 0.000100  loss: 0.4830 (0.5429)  CLS_Loss: 0.4830 (0.5429)  time: 0.1118  data: 0.0001  max mem: 1387\n",
      "Epoch: [11]  [30/80]  eta: 0:00:06  lr: 0.000100  loss: 0.4174 (0.5319)  CLS_Loss: 0.4174 (0.5319)  time: 0.1251  data: 0.0001  max mem: 1387\n",
      "Epoch: [11]  [40/80]  eta: 0:00:04  lr: 0.000100  loss: 0.4097 (0.5202)  CLS_Loss: 0.4097 (0.5202)  time: 0.1078  data: 0.0001  max mem: 1387\n",
      "Epoch: [11]  [50/80]  eta: 0:00:03  lr: 0.000100  loss: 0.4398 (0.5091)  CLS_Loss: 0.4398 (0.5091)  time: 0.0979  data: 0.0001  max mem: 1387\n",
      "Epoch: [11]  [60/80]  eta: 0:00:02  lr: 0.000100  loss: 0.4681 (0.5142)  CLS_Loss: 0.4681 (0.5142)  time: 0.0968  data: 0.0001  max mem: 1387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11]  [70/80]  eta: 0:00:01  lr: 0.000100  loss: 0.5122 (0.5193)  CLS_Loss: 0.5122 (0.5193)  time: 0.0892  data: 0.0002  max mem: 1387\n",
      "Epoch: [11]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5017 (0.5264)  CLS_Loss: 0.5017 (0.5264)  time: 0.0858  data: 0.0001  max mem: 1387\n",
      "Epoch: [11] Total time: 0:00:08 (0.1084 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.5263824, 'CLS_Loss': 0.5263824}\n",
      "Valid:  [  0/100]  eta: 0:00:35  loss: 1.8008 (1.8008)  CLS_Loss: 1.8008 (1.8008)  time: 0.3570  data: 0.3385  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:03  loss: 0.2339 (0.8611)  CLS_Loss: 0.2339 (0.8611)  time: 0.0436  data: 0.0309  max mem: 1387\n",
      "Valid:  [ 20/100]  eta: 0:00:02  loss: 0.2585 (0.6458)  CLS_Loss: 0.2585 (0.6458)  time: 0.0122  data: 0.0002  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.2702 (0.6043)  CLS_Loss: 0.2702 (0.6043)  time: 0.0120  data: 0.0002  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:01  loss: 0.2702 (0.5411)  CLS_Loss: 0.2702 (0.5411)  time: 0.0119  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:00  loss: 0.2818 (0.5586)  CLS_Loss: 0.2818 (0.5586)  time: 0.0132  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.2035 (0.4908)  CLS_Loss: 0.2035 (0.4908)  time: 0.0144  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.2013 (0.4740)  CLS_Loss: 0.2013 (0.4740)  time: 0.0137  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.2115 (0.4695)  CLS_Loss: 0.2115 (0.4695)  time: 0.0131  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.2349 (0.5060)  CLS_Loss: 0.2349 (0.5060)  time: 0.0136  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.2536 (0.5286)  CLS_Loss: 0.2536 (0.5286)  time: 0.0140  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:01 (0.0180 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.5285777, 'CLS_Loss': 0.5285777, 'auc': 0.6820175, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [12]  [ 0/80]  eta: 0:00:37  lr: 0.000100  loss: 0.4052 (0.4052)  CLS_Loss: 0.4052 (0.4052)  time: 0.4675  data: 0.4353  max mem: 1387\n",
      "Epoch: [12]  [10/80]  eta: 0:00:05  lr: 0.000100  loss: 0.4019 (0.4556)  CLS_Loss: 0.4019 (0.4556)  time: 0.0843  data: 0.0397  max mem: 1387\n",
      "Epoch: [12]  [20/80]  eta: 0:00:05  lr: 0.000100  loss: 0.4128 (0.4707)  CLS_Loss: 0.4128 (0.4707)  time: 0.0653  data: 0.0001  max mem: 1387\n",
      "Epoch: [12]  [30/80]  eta: 0:00:04  lr: 0.000100  loss: 0.5251 (0.5104)  CLS_Loss: 0.5251 (0.5104)  time: 0.0914  data: 0.0002  max mem: 1387\n",
      "Epoch: [12]  [40/80]  eta: 0:00:03  lr: 0.000100  loss: 0.5614 (0.5221)  CLS_Loss: 0.5614 (0.5221)  time: 0.0925  data: 0.0002  max mem: 1387\n",
      "Epoch: [12]  [50/80]  eta: 0:00:02  lr: 0.000100  loss: 0.5469 (0.5398)  CLS_Loss: 0.5469 (0.5398)  time: 0.0871  data: 0.0002  max mem: 1387\n",
      "Epoch: [12]  [60/80]  eta: 0:00:01  lr: 0.000100  loss: 0.5469 (0.5369)  CLS_Loss: 0.5469 (0.5369)  time: 0.0910  data: 0.0001  max mem: 1387\n",
      "Epoch: [12]  [70/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4638 (0.5232)  CLS_Loss: 0.4638 (0.5232)  time: 0.1137  data: 0.0002  max mem: 1387\n",
      "Epoch: [12]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4638 (0.5233)  CLS_Loss: 0.4638 (0.5233)  time: 0.1320  data: 0.0001  max mem: 1387\n",
      "Epoch: [12] Total time: 0:00:08 (0.1010 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.5233306, 'CLS_Loss': 0.5233306}\n",
      "Valid:  [  0/100]  eta: 0:00:39  loss: 0.4664 (0.4664)  CLS_Loss: 0.4664 (0.4664)  time: 0.3987  data: 0.3792  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:04  loss: 0.2024 (0.4492)  CLS_Loss: 0.2024 (0.4492)  time: 0.0507  data: 0.0346  max mem: 1387\n",
      "Valid:  [ 20/100]  eta: 0:00:02  loss: 0.1618 (0.4985)  CLS_Loss: 0.1618 (0.4985)  time: 0.0160  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.1243 (0.3800)  CLS_Loss: 0.1243 (0.3800)  time: 0.0156  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:01  loss: 0.1384 (0.4177)  CLS_Loss: 0.1384 (0.4177)  time: 0.0151  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:01  loss: 0.1645 (0.4697)  CLS_Loss: 0.1645 (0.4697)  time: 0.0147  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.1855 (0.4933)  CLS_Loss: 0.1855 (0.4933)  time: 0.0126  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.1652 (0.4815)  CLS_Loss: 0.1652 (0.4815)  time: 0.0109  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.1781 (0.5578)  CLS_Loss: 0.1781 (0.5578)  time: 0.0105  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.1912 (0.5366)  CLS_Loss: 0.1912 (0.5366)  time: 0.0104  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.1717 (0.5171)  CLS_Loss: 0.1717 (0.5171)  time: 0.0116  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:01 (0.0185 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.5170522, 'CLS_Loss': 0.5170522, 'auc': 0.7516447, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [13]  [ 0/80]  eta: 0:00:33  lr: 0.000100  loss: 0.7802 (0.7802)  CLS_Loss: 0.7802 (0.7802)  time: 0.4172  data: 0.3870  max mem: 1387\n",
      "Epoch: [13]  [10/80]  eta: 0:00:06  lr: 0.000100  loss: 0.5023 (0.5649)  CLS_Loss: 0.5023 (0.5649)  time: 0.0862  data: 0.0353  max mem: 1387\n",
      "Epoch: [13]  [20/80]  eta: 0:00:04  lr: 0.000100  loss: 0.4110 (0.5410)  CLS_Loss: 0.4110 (0.5410)  time: 0.0544  data: 0.0002  max mem: 1387\n",
      "Epoch: [13]  [30/80]  eta: 0:00:03  lr: 0.000100  loss: 0.4016 (0.4970)  CLS_Loss: 0.4016 (0.4970)  time: 0.0513  data: 0.0002  max mem: 1387\n",
      "Epoch: [13]  [40/80]  eta: 0:00:02  lr: 0.000100  loss: 0.4236 (0.5228)  CLS_Loss: 0.4236 (0.5228)  time: 0.0437  data: 0.0002  max mem: 1387\n",
      "Epoch: [13]  [50/80]  eta: 0:00:01  lr: 0.000100  loss: 0.5149 (0.5385)  CLS_Loss: 0.5149 (0.5385)  time: 0.0403  data: 0.0001  max mem: 1387\n",
      "Epoch: [13]  [60/80]  eta: 0:00:01  lr: 0.000100  loss: 0.5917 (0.5431)  CLS_Loss: 0.5917 (0.5431)  time: 0.0404  data: 0.0001  max mem: 1387\n",
      "Epoch: [13]  [70/80]  eta: 0:00:00  lr: 0.000100  loss: 0.4656 (0.5267)  CLS_Loss: 0.4656 (0.5267)  time: 0.0498  data: 0.0002  max mem: 1387\n",
      "Epoch: [13]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5043 (0.5343)  CLS_Loss: 0.5043 (0.5343)  time: 0.0707  data: 0.0001  max mem: 1387\n",
      "Epoch: [13] Total time: 0:00:04 (0.0594 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.534321, 'CLS_Loss': 0.534321}\n",
      "Valid:  [  0/100]  eta: 0:00:38  loss: 0.1011 (0.1011)  CLS_Loss: 0.1011 (0.1011)  time: 0.3895  data: 0.3664  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:04  loss: 0.2450 (0.6756)  CLS_Loss: 0.2450 (0.6756)  time: 0.0527  data: 0.0334  max mem: 1387\n",
      "Valid:  [ 20/100]  eta: 0:00:02  loss: 0.2124 (0.5967)  CLS_Loss: 0.2124 (0.5967)  time: 0.0180  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:02  loss: 0.1927 (0.4754)  CLS_Loss: 0.1927 (0.4754)  time: 0.0175  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:01  loss: 0.2103 (0.4678)  CLS_Loss: 0.2103 (0.4678)  time: 0.0176  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:01  loss: 0.2495 (0.5046)  CLS_Loss: 0.2495 (0.5046)  time: 0.0162  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.1935 (0.4720)  CLS_Loss: 0.1935 (0.4720)  time: 0.0162  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.1860 (0.4510)  CLS_Loss: 0.1860 (0.4510)  time: 0.0174  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.1929 (0.4801)  CLS_Loss: 0.1929 (0.4801)  time: 0.0163  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.1816 (0.5028)  CLS_Loss: 0.1816 (0.5028)  time: 0.0147  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.2404 (0.5246)  CLS_Loss: 0.2404 (0.5246)  time: 0.0149  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:02 (0.0215 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.5245983, 'CLS_Loss': 0.5245983, 'auc': 0.7105263, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [14]  [ 0/80]  eta: 0:00:39  lr: 0.000100  loss: 0.5393 (0.5393)  CLS_Loss: 0.5393 (0.5393)  time: 0.4895  data: 0.4334  max mem: 1387\n",
      "Epoch: [14]  [10/80]  eta: 0:00:11  lr: 0.000100  loss: 0.4728 (0.4634)  CLS_Loss: 0.4728 (0.4634)  time: 0.1648  data: 0.0395  max mem: 1387\n",
      "Epoch: [14]  [20/80]  eta: 0:00:08  lr: 0.000100  loss: 0.4497 (0.5070)  CLS_Loss: 0.4497 (0.5070)  time: 0.1193  data: 0.0002  max mem: 1387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [14]  [30/80]  eta: 0:00:06  lr: 0.000100  loss: 0.4497 (0.4893)  CLS_Loss: 0.4497 (0.4893)  time: 0.1048  data: 0.0002  max mem: 1387\n",
      "Epoch: [14]  [40/80]  eta: 0:00:04  lr: 0.000100  loss: 0.4418 (0.4861)  CLS_Loss: 0.4418 (0.4861)  time: 0.0976  data: 0.0001  max mem: 1387\n",
      "Epoch: [14]  [50/80]  eta: 0:00:03  lr: 0.000100  loss: 0.4255 (0.4897)  CLS_Loss: 0.4255 (0.4897)  time: 0.0679  data: 0.0001  max mem: 1387\n",
      "Epoch: [14]  [60/80]  eta: 0:00:01  lr: 0.000100  loss: 0.4352 (0.4941)  CLS_Loss: 0.4352 (0.4941)  time: 0.0472  data: 0.0001  max mem: 1387\n",
      "Epoch: [14]  [70/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5323 (0.5050)  CLS_Loss: 0.5323 (0.5050)  time: 0.0528  data: 0.0001  max mem: 1387\n",
      "Epoch: [14]  [79/80]  eta: 0:00:00  lr: 0.000100  loss: 0.5323 (0.5068)  CLS_Loss: 0.5323 (0.5068)  time: 0.0542  data: 0.0001  max mem: 1387\n",
      "Epoch: [14] Total time: 0:00:07 (0.0879 s / it)\n",
      "Averaged train_stats:  {'lr': 0.0001, 'loss': 0.5068171, 'CLS_Loss': 0.5068171}\n",
      "Valid:  [  0/100]  eta: 0:00:37  loss: 0.1497 (0.1497)  CLS_Loss: 0.1497 (0.1497)  time: 0.3770  data: 0.3608  max mem: 1387\n",
      "Valid:  [ 10/100]  eta: 0:00:04  loss: 0.1605 (1.0247)  CLS_Loss: 0.1605 (1.0247)  time: 0.0450  data: 0.0329  max mem: 1387\n",
      "Valid:  [ 20/100]  eta: 0:00:02  loss: 0.1973 (0.7713)  CLS_Loss: 0.1973 (0.7713)  time: 0.0115  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 30/100]  eta: 0:00:01  loss: 0.1944 (0.5841)  CLS_Loss: 0.1944 (0.5841)  time: 0.0112  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 40/100]  eta: 0:00:01  loss: 0.1944 (0.5930)  CLS_Loss: 0.1944 (0.5930)  time: 0.0109  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 50/100]  eta: 0:00:00  loss: 0.1725 (0.5650)  CLS_Loss: 0.1725 (0.5650)  time: 0.0105  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 60/100]  eta: 0:00:00  loss: 0.1725 (0.5263)  CLS_Loss: 0.1725 (0.5263)  time: 0.0102  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 70/100]  eta: 0:00:00  loss: 0.2434 (0.5367)  CLS_Loss: 0.2434 (0.5367)  time: 0.0106  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 80/100]  eta: 0:00:00  loss: 0.2866 (0.5419)  CLS_Loss: 0.2866 (0.5419)  time: 0.0111  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 90/100]  eta: 0:00:00  loss: 0.2908 (0.5678)  CLS_Loss: 0.2908 (0.5678)  time: 0.0114  data: 0.0001  max mem: 1387\n",
      "Valid:  [ 99/100]  eta: 0:00:00  loss: 0.1779 (0.5359)  CLS_Loss: 0.1779 (0.5359)  time: 0.0111  data: 0.0001  max mem: 1387\n",
      "Valid: Total time: 0:00:01 (0.0162 s / it)\n",
      "Averaged valid_stats:  {'loss': 0.5358853, 'CLS_Loss': 0.5358853, 'auc': 0.685307, 'f1': 0.0, 'acc': 0.76, 'sen': 0.0, 'spe': 1.0}\n",
      "Epoch: [15]  [ 0/80]  eta: 0:00:37  lr: 0.000100  loss: 0.3528 (0.3528)  CLS_Loss: 0.3528 (0.3528)  time: 0.4690  data: 0.4061  max mem: 1387\n",
      "Epoch: [15]  [10/80]  eta: 0:00:11  lr: 0.000100  loss: 0.3685 (0.4550)  CLS_Loss: 0.3685 (0.4550)  time: 0.1620  data: 0.0371  max mem: 1387\n",
      "Epoch: [15]  [20/80]  eta: 0:00:08  lr: 0.000100  loss: 0.4593 (0.4645)  CLS_Loss: 0.4593 (0.4645)  time: 0.1320  data: 0.0002  max mem: 1387\n",
      "Epoch: [15]  [30/80]  eta: 0:00:06  lr: 0.000100  loss: 0.4593 (0.4780)  CLS_Loss: 0.4593 (0.4780)  time: 0.1179  data: 0.0001  max mem: 1387\n",
      "Epoch: [15]  [40/80]  eta: 0:00:05  lr: 0.000100  loss: 0.5116 (0.5241)  CLS_Loss: 0.5116 (0.5241)  time: 0.1046  data: 0.0002  max mem: 1387\n",
      "Epoch: [15]  [50/80]  eta: 0:00:03  lr: 0.000100  loss: 0.5332 (0.5296)  CLS_Loss: 0.5332 (0.5296)  time: 0.0985  data: 0.0002  max mem: 1387\n",
      "Epoch: [15]  [60/80]  eta: 0:00:02  lr: 0.000100  loss: 0.5269 (0.5399)  CLS_Loss: 0.5269 (0.5399)  time: 0.0878  data: 0.0001  max mem: 1387\n",
      "Epoch: [15]  [70/80]  eta: 0:00:01  lr: 0.000100  loss: 0.4827 (0.5248)  CLS_Loss: 0.4827 (0.5248)  time: 0.0782  data: 0.0001  max mem: 1387\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0edf666d0161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetric_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_every\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0minput\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mcls_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import torch\n",
    "import utils\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from metrics import *\n",
    "from losses import soft_dice_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print_freq = 10\n",
    "output_dir = './checkpoints/stl_cls/'\n",
    "device     = 'cuda'\n",
    "\n",
    "# Whole LOOP\n",
    "for epoch in range(0, 200):\n",
    "    \n",
    "    ################################################################################################\n",
    "    # Training \n",
    "    ################################################################################################\n",
    "    \n",
    "    model.train(True)\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \", n=10)\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "    \n",
    "    for batch_data in metric_logger.log_every(data_loader_train, print_freq, header):\n",
    "        \n",
    "        input  = batch_data[0].to(device).float()\n",
    "        cls_gt = batch_data[1].to(device).float()\n",
    "\n",
    "        cls_pred = model(input)\n",
    "\n",
    "        loss, loss_detail = criterion(cls_pred=cls_pred, cls_gt=cls_gt)\n",
    "        \n",
    "        loss_value = loss.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metric_logger.update(loss=loss_value)\n",
    "        if loss_detail is not None:\n",
    "            metric_logger.update(**loss_detail)\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "    \n",
    "    train_stats = {k: round(meter.global_avg, 7) for k, meter in metric_logger.meters.items()}\n",
    "    print(\"Averaged train_stats: \", train_stats)\n",
    "    \n",
    "    ################################################################################################\n",
    "    # Validation\n",
    "    ################################################################################################\n",
    "    \n",
    "    model.eval()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \", n=1)\n",
    "    header = 'Valid:'\n",
    "\n",
    "    total_cls_pred  = torch.tensor([])\n",
    "    total_cls_true  = torch.tensor([])\n",
    "    \n",
    "    for batch_data in metric_logger.log_every(data_loader_valid, print_freq, header):\n",
    "        \n",
    "        input  = batch_data[0].to(device).float()\n",
    "        cls_gt = batch_data[1].to(device).float()\n",
    "\n",
    "        cls_pred = model(input)\n",
    "\n",
    "        loss, loss_detail = criterion(cls_pred=cls_pred, cls_gt=cls_gt)\n",
    "\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "\n",
    "        # LOSS\n",
    "        metric_logger.update(loss=loss_value)        \n",
    "        if loss_detail is not None:\n",
    "            metric_logger.update(**loss_detail)\n",
    "\n",
    "        # post-processing\n",
    "        cls_pred = torch.sigmoid(cls_pred)\n",
    "\n",
    "        total_cls_pred  = torch.cat([total_cls_pred, cls_pred.detach().cpu()])\n",
    "        total_cls_true  = torch.cat([total_cls_true, cls_gt.detach().cpu()])\n",
    "\n",
    "\n",
    "    # Metric CLS\n",
    "    auc            = roc_auc_score(y_true=total_cls_true, y_score=total_cls_pred)\n",
    "    tp, fp, fn, tn = get_stats(total_cls_pred.round().long(), total_cls_true.long(), mode=\"binary\")        \n",
    "    f1             = f1_score(tp, fp, fn, tn, reduction=\"macro\")\n",
    "    acc            = accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
    "    sen            = sensitivity(tp, fp, fn, tn, reduction=\"macro\")\n",
    "    spe            = specificity(tp, fp, fn, tn, reduction=\"macro\")\n",
    "\n",
    "    metric_logger.update(auc=auc, f1=f1, acc=acc, sen=sen, spe=spe)          \n",
    "    \n",
    "    valid_stats = {k: round(meter.global_avg, 7) for k, meter in metric_logger.meters.items()}\n",
    "    print(\"Averaged valid_stats: \", valid_stats)\n",
    "    \n",
    "    ################################################################################################\n",
    "    # Save & Log\n",
    "    ################################################################################################\n",
    "    \n",
    "    checkpoint_paths = output_dir + '/epoch_' + str(epoch) + '_checkpoint.pth'\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }, checkpoint_paths)\n",
    "\n",
    "    log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
    "                **{f'valid_{k}': v for k, v in valid_stats.items()},\n",
    "                'epoch': epoch}\n",
    "\n",
    "    if output_dir:\n",
    "        with open(output_dir + \"/log.txt\", \"a\") as f:\n",
    "            f.write(json.dumps(log_stats) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_log(path):\n",
    "    log_list = []\n",
    "    lines = open(path, 'r').read().splitlines() \n",
    "    for i in range(len(lines)):\n",
    "        exec('log_list.append('+lines[i] + ')')\n",
    "    return  log_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_list = read_log(path = '/workspace/sunggu/6.Kakao/checkpoints/[Baseline]Face_Net_DAC_fold0_upsample/log.txt')\n",
    "print(log_list[0].keys())\n",
    "result_dict = {}\n",
    "\n",
    "for key in log_list[0].keys():\n",
    "    exec( \"result_dict['\"+str(key)+\"']\" + \" = [ log_list[i]['\"+str(key)+\"'] for i in range(len(log_list)) ]\")\n",
    "\n",
    "for key in result_dict.keys():\n",
    "    plt.plot(result_dict[key])\n",
    "    plt.title(key)\n",
    "    print(\"###########################################################\")\n",
    "    print(\"Argsort = \", np.argsort(result_dict[key])[:5])\n",
    "    print(\"Value   = \", [result_dict[key][i] for i in np.argsort(result_dict[key])[:5]])\n",
    "    plt.show()\n",
    "    \n",
    "    if key == 'valid_loss':\n",
    "        print(\"Valid_Loss = \", np.argsort(result_dict[key])[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log check\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_log(path):\n",
    "    log_list = []\n",
    "    lines = open(path, 'r').read().splitlines() \n",
    "    for i in range(len(lines)):\n",
    "        exec('log_list.append('+lines[i] + ')')\n",
    "    return  log_list\n",
    "\n",
    "51, 36, 35\n",
    "\n",
    "log_list = read_log(path = '/workspace/sunggu/6.Kakao/checkpoints/[Baseline]Face_Net_DAC_fold0_upsample/log.txt')\n",
    "print(log_list[0].keys())\n",
    "result_dict = {}\n",
    "\n",
    "for key in log_list[0].keys():\n",
    "    exec( \"result_dict['\"+str(key)+\"']\" + \" = [ log_list[i]['\"+str(key)+\"'] for i in range(len(log_list)) ]\")\n",
    "\n",
    "for key in result_dict.keys():\n",
    "    plt.plot(result_dict[key])\n",
    "    plt.title(key)\n",
    "    print(\"###########################################################\")\n",
    "    print(\"Argsort = \", np.argsort(result_dict[key])[:5])\n",
    "    print(\"Value   = \", [result_dict[key][i] for i in np.argsort(result_dict[key])[:5]])\n",
    "    plt.show()\n",
    "    \n",
    "    if key == 'valid_loss':\n",
    "        print(\"Valid_Loss = \", np.argsort(result_dict[key])[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "\n",
    "print(\"Loading... Resume\")\n",
    "checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])        \n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])        \n",
    "args.start_epoch = checkpoint['epoch'] + 1  \n",
    "try:\n",
    "    log_path = os.path.dirname(args.resume)+'/log.txt'\n",
    "    lines    = open(log_path,'r').readlines()\n",
    "    val_loss_list = []\n",
    "    for l in lines:\n",
    "        exec('log_dict='+l.replace('NaN', '0'))\n",
    "        val_loss_list.append(log_dict['valid_loss'])\n",
    "    print(\"Epoch: \", np.argmin(val_loss_list), \" Minimum Val Loss ==> \", np.min(val_loss_list))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "STL_cls.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
